{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6db9f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "token_1 = os.getenv(\"token_1\")\n",
    "token_2 = os.getenv(\"token_2\")\n",
    "token_3 = os.getenv(\"token_3\")\n",
    "endpoint = os.getenv(\"endpoint\")\n",
    "model_name = os.getenv(\"model_name\")\n",
    "\n",
    "\n",
    "client_1 = OpenAI(\n",
    "    base_url=endpoint,\n",
    "    api_key=token_1,\n",
    ")\n",
    "client_2 = OpenAI(\n",
    "    base_url=endpoint,\n",
    "    api_key=token_2,\n",
    ")\n",
    "client_3= OpenAI(\n",
    "    base_url=endpoint,\n",
    "    api_key=token_3,\n",
    ")\n",
    "\n",
    "client_list = [client_1, client_2, client_3]\n",
    "client = client_list*len(client_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d532c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def api_call(input_prompt: str):\n",
    "    for i in range(len(client)):\n",
    "        try:\n",
    "            completion = client[i].chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": input_prompt\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            print(f\"-----Call api with request: {input_prompt} with iter {i} -----\\n\")\n",
    "            content = completion.choices[0].message.content\n",
    "            # content = \"[\" + content.split(\"[\")[-1].split(\"]\")[0] + \"]\"\n",
    "            content = '[\"' + content.split(\"[\")[-1].split(\"]\")[0] + '\"]'\n",
    "            return json.loads(content)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"error: {e}, wil continue\")\n",
    "            continue\n",
    "    raise Exception(\"Error: Retried 3 times!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcf0950c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Call api with request: Who are you? with iter 0 -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = api_call(\"Who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76928468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I am an AI assistant designed to help you! Think of me as a tool to assist with answering questions, offering guidance, solving problems, or just chatting. If there's anything you'd like to know or discuss, feel free to ask! What's on your mind? ðŸ˜Š\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9cb239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/nnminh322/researchMS.git\n",
    "# %cd /kaggle/working/researchMS/FCED\n",
    "# !pip install uv\n",
    "# !uv pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc250e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ(\"token_1\") = \"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\"\n",
    "# os.environ(\"token_2\") = \"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\"\n",
    "# os.environ(\"token_3\") = \"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\"\n",
    "# os.environ(\"endpoint\") = \"https://models.github.ai/inference\"\n",
    "# os.environ(\"model_name\") = \"openai/gpt-4o\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
